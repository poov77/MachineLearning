{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d083530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Spam Classification with Large Dataset\n",
      "==================================================\n",
      "Loading dataset...\n",
      "Attempting to load: emails.csv\n",
      "✅ File loaded successfully! Shape: (5172, 3002)\n",
      "📋 Columns found: ['Email No.', 'the', 'to', 'ect', 'and', 'for', 'of', 'a', 'you', 'hou', 'in', 'on', 'is', 'this', 'enron', 'i', 'be', 'that', 'will', 'have', 'with', 'your', 'at', 'we', 's', 'are', 'it', 'by', 'com', 'as', 'from', 'gas', 'or', 'not', 'me', 'deal', 'if', 'meter', 'hpl', 'please', 're', 'e', 'any', 'our', 'corp', 'can', 'd', 'all', 'has', 'was', 'know', 'need', 'an', 'forwarded', 'new', 't', 'may', 'up', 'j', 'mmbtu', 'should', 'do', 'am', 'get', 'out', 'see', 'no', 'there', 'price', 'daren', 'but', 'been', 'company', 'l', 'these', 'let', 'so', 'would', 'm', 'into', 'xls', 'farmer', 'attached', 'us', 'information', 'they', 'message', 'day', 'time', 'my', 'one', 'what', 'only', 'http', 'th', 'volume', 'mail', 'contract', 'which', 'month', 'more', 'robert', 'sitara', 'about', 'texas', 'nom', 'energy', 'pec', 'questions', 'www', 'deals', 'volumes', 'pm', 'ena', 'now', 'their', 'file', 'some', 'email', 'just', 'also', 'call', 'change', 'other', 'here', 'like', 'b', 'flow', 'net', 'following', 'p', 'production', 'when', 'over', 'back', 'want', 'original', 'them', 'below', 'o', 'ticket', 'c', 'he', 'could', 'make', 'inc', 'report', 'march', 'contact', 'were', 'days', 'list', 'nomination', 'system', 'who', 'april', 'number', 'sale', 'don', 'its', 'first', 'thanks', 'business', 'help', 'per', 'through', 'july', 'forward', 'font', 'free', 'daily', 'use', 'order', 'today', 'r', 'had', 'fw', 'set', 'plant', 'statements', 'go', 'gary', 'oil', 'line', 'sales', 'w', 'effective', 'well', 'tenaska', 'take', 'june', 'x', 'within', 'nbsp', 'she', 'how', 'north', 'america', 'being', 'under', 'next', 'week', 'than', 'january', 'last', 'two', 'service', 'purchase', 'name', 'less', 'height', 'off', 'agreement', 'k', 'work', 'tap', 'group', 'year', 'based', 'transport', 'after', 'think', 'made', 'each', 'available', 'changes', 'due', 'f', 'h', 'services', 'smith', 'send', 'management', 'stock', 'sent', 'll', 'co', 'office', 'needs', 'cotten', 'did', 'actuals', 'u', 'money', 'before', 'looking', 'then', 'pills', 'online', 'request', 'look', 'desk', 'ami', 'his', 'same', 'george', 'chokshi', 'point', 'delivery', 'friday', 'does', 'size', 'august', 'product', 'pat', 'width', 'iv', 'noms', 'address', 'above', 'sure', 'give', 'october', 'future', 'find', 'market', 'n', 'mary', 'vance', 'melissa', 'said', 'internet', 'still', 'account', 'those', 'down', 'link', 'hsc', 'rate', 'people', 'pipeline', 'best', 'actual', 'very', 'end', 'home', 'houston', 'tu', 'high', 'her', 'team', 'products', 'many', 'currently', 'spot', 'receive', 'good', 'such', 'going', 'process', 'feb', 'monday', 'info', 'david', 'lloyd', 'again', 'both', 'click', 'subject', 'jackie', 'december', 'total', 'na', 'lisa', 've', 'september', 'hours', 'until', 'resources', 'because', 'aol', 'february', 'where', 'g', 'investment', 'issue', 'duke', 'since', 'pay', 'show', 'way', 'global', 'computron', 'further', 'most', 'place', 'offer', 'natural', 'activity', 'eastrans', 'graves', 'right', 'prices', 'date', 'john', 'utilities', 'november', 'clynes', 'jan', 'securities', 'meeting', 'susan', 'hplc', 'julie', 'able', 'received', 'align', 'term', 'id', 'revised', 'thursday', 'pg', 'fee', 'hplno', 'trading', 'additional', 'site', 'txu', 'data', 'wellhead', 'reply', 'taylor', 'news', 'unify', 'michael', 'provide', 'note', 'much', 'access', 'lannou', 'every', 'between', 'keep', 'tuesday', 'review', 'great', 'tom', 'put', 'done', 'long', 'save', 'section', 'must', 'v', 'part', 'nd', 'million', 'check', 'trade', 'bob', 'created', 'steve', 'prior', 'copy', 'continue', 'numbers', 'via', 'world', 'demand', 'hanks', 'contracts', 'phone', 'transaction', 'customer', 'possible', 'pefs', 'meyers', 'months', 'special', 'without', 'used', 'regarding', 'software', 'howard', 'support', 'buy', 'young', 'meters', 'thru', 'believe', 'gcs', 'cec', 'entered', 'control', 'dec', 'face', 'create', 'weissman', 'st', 'color', 'come', 'supply', 'brian', 'hplo', 'own', 'correct', 'customers', 'web', 'allocation', 'soon', 'using', 'development', 'mark', 'low', 'power', 'problem', 'once', 'however', 'tickets', 'border', 'performance', 'manager', 'rates', 'center', 'companies', 'risk', 'details', 'needed', 'international', 'field', 'even', 'someone', 'doc', 'fuel', 'lee', 'paid', 'while', 'start', 'index', 'include', 'nominations', 'act', 'pricing', 'scheduled', 'gathering', 'type', 'href', 'during', 'aimee', 'anything', 'feel', 'fuels', 'getting', 'advice', 'why', 'increase', 'path', 'sell', 'works', 'issues', 'three', 'enronxgate', 'camp', 'either', 'form', 'security', 'interest', 'financial', 'family', 'xp', 'plan', 'current', 'top', 'another', 'src', 'spreadsheet', 'allen', 'wednesday', 'read', 'him', 'working', 'wynne', 'add', 'deliveries', 'buyback', 'allocated', 'firm', 'james', 'marketing', 'tx', 'results', 'got', 'stocks', 'calpine', 'might', 'operations', 'position', 'logistics', 'fax', 'cost', 'party', 'zero', 'pops', 'old', 'pt', 'scheduling', 'flowed', 'dollars', 'update', 'gco', 'katy', 'including', 'follow', 'yahoo', 'already', 'suite', 'error', 'past', 'page', 'stop', 'changed', 'book', 'program', 'few', 'better', 'operating', 'equistar', 'move', 'cotton', 'aep', 'y', 'state', 'ees', 'rita', 'provided', 'employees', 'period', 'morning', 'cd', 'hotmail', 'entex', 'swing', 'real', 'exchange', 'tomorrow', 'lst', 'counterparty', 'parker', 'person', 'follows', 'valid', 'visit', 'little', 'professional', 'quality', 'confirm', 'something', 'megan', 'brenda', 'around', 'windows', 'im', 'storage', 'accounting', 'called', 'ranch', 'tax', 'problems', 'case', 'teco', 'fact', 'always', 'too', 'unsubscribe', 'amount', 'coastal', 'never', 'rodriguez', 'love', 'acton', 'shut', 'pipe', 'project', 'hope', 'limited', 'invoice', 'credit', 'full', 'survey', 'ray', 'carlos', 'anyone', 'wanted', 'yet', 'ic', 'scott', 'years', 'charlie', 'soft', 'notice', 'advise', 'addition', 'donald', 'lsk', 'wish', 'katherine', 'website', 'hplnl', 'schumack', 'prescription', 'cover', 'shares', 'cash', 'imbalance', 'united', 'handle', 'big', 'everyone', 'style', 'clear', 'producer', 'weekend', 'city', 'requested', 'stone', 'left', 'payment', 'mobil', 'shows', 'small', 'confirmed', 'technology', 'meet', 'extend', 'life', 'intended', 'sherlyn', 'schedule', 'else', 'letter', 'box', 'bill', 'richard', 'lamphier', 'complete', 'ever', 'release', 'newsletter', 'anita', 'clem', 'having', 'herod', 'beginning', 'papayoti', 'try', 'mike', 'enter', 'estimates', 'location', 'cut', 'question', 'things', 'personal', 'feedback', 'cialis', 'found', 'area', 'dow', 'terms', 'central', 'necessary', 'man', 'run', 'reason', 'third', 'midcon', 'charge', 'president', 'de', 'listed', 'meds', 'thomas', 'thought', 'capital', 'added', 'ask', 'weeks', 'investing', 'commercial', 'star', 'several', 'easy', 'view', 'cannot', 'extended', 'lauri', 'beaumont', 'union', 'times', 'open', 'cause', 'monthly', 'action', 'offers', 'industry', 'states', 'side', 'mailto', 'probably', 'neal', 'second', 'stephanie', 'download', 'flash', 'agree', 'mcf', 'transfer', 'doing', 'important', 'basis', 'different', 'final', 'koch', 'exxon', 'remove', 'microsoft', 'interested', 'application', 'sept', 'mg', 'write', 'lp', 'east', 'requirements', 'code', 'value', 'thank', 'together', 'exploration', 'mid', 'dfarmer', 'everything', 'receipt', 'thu', 'afternoon', 'late', 'enserch', 'coming', 'bank', 'response', 'tell', 'shipping', 'night', 'events', 'cynthia', 'lsp', 'close', 'legal', 'country', 'direct', 'expected', 'ces', 'corporation', 'options', 'really', 'voip', 'nominated', 'etc', 'latest', 'potential', 'priced', 'edward', 'valero', 'material', 'stack', 'victor', 'redeliveries', 'loss', 'remember', 'baumbach', 'option', 'private', 'longer', 'aware', 'included', 'drugs', 'public', 'reinhardt', 'version', 'hesse', 'discuss', 'related', 'asked', 'say', 'viagra', 'revision', 'bgcolor', 'kind', 'pro', 'completed', 'health', 'ready', 'plans', 'registered', 'regards', 'carthage', 'zone', 'fill', 'away', 'computer', 'systems', 'industrial', 'mentioned', 'told', 'therefore', 'growth', 'sold', 'track', 'reports', 'south', 'rd', 'jim', 'costs', 'image', 'expect', 'return', 'physical', 'el', 'browser', 'donna', 'stacey', 'begin', 'china', 'duty', 'approximately', 'showing', 'unit', 'jones', 'hard', 'verify', 'updated', 'eol', 'cs', 'orders', 'talk', 'trying', 'base', 'given', 'server', 'source', 'pathed', 'strong', 'bryan', 'directly', 'risks', 'whole', 'major', 'users', 'purchases', 'oo', 'karen', 'luong', 'level', 'required', 'delivered', 'portfolio', 'riley', 'ali', 'easttexas', 'poorman', 'bellamy', 'assistance', 'nothing', 'gif', 'thing', 'retail', 'didn', 'valley', 'department', 'cleburne', 'allow', 'gpgfin', 'answer', 'items', 'paste', 'avila', 'taken', 'mm', 'nguyen', 'ensure', 'reference', 'hall', 'later', 'lone', 'user', 'methanol', 'facility', 'network', 'spoke', 'though', 'tabs', 'taking', 'status', 'considered', 'purchased', 'says', 'yourself', 'paliourg', 'dy', 'jeff', 'businesses', 'fred', 'transportation', 'apache', 'morris', 'nov', 'ltd', 'brand', 'federal', 'statement', 'oasis', 'reflect', 'assets', 'lamadrid', 'general', 'bridge', 'ability', 'oct', 'play', 'enrononline', 'compliance', 'spam', 'availability', 'king', 'understanding', 'chance', 'quick', 'effort', 'points', 'reliantenergy', 'fixed', 'short', 'hill', 'cheryl', 'aepin', 'key', 'understand', 'valign', 'capacity', 'game', 'took', 'bring', 'guys', 'god', 'green', 'care', 'withers', 'property', 'hub', 'johnson', 'employee', 'wants', 'albrecht', 'meaning', 'expectations', 'mx', 'moved', 'cernosek', 'matter', 'devon', 'calls', 'worldwide', 'records', 'removed', 'lose', 'large', 'referenced', 'walker', 'iferc', 'enw', 'ponton', 'eileen', 'ship', 'upon', 'enerfin', 'jennifer', 'looks', 'staff', 'pc', 'target', 'waha', 'making', 'cp', 'impact', 'partner', 'immediately', 'shall', 'channel', 'takes', 'sat', 'others', 'hear', 'went', 'travel', 'listing', 'approved', 'processing', 'early', 'enough', 'sally', 'starting', 'distribution', 'tejas', 'transactions', 'stay', 'earl', 'superty', 'doesn', 'reserves', 'includes', 'choose', 'adobe', 'publisher', 'paso', 'cornhusker', 'training', 'markets', 'content', 'solution', 'shell', 'jpg', 'print', 'drive', 'pain', 'password', 'half', 'herrera', 'saturday', 'moopid', 'hotlist', 'balance', 'super', 'vacation', 'sex', 'happy', 'excess', 'existing', 'fund', 'stella', 'share', 'sign', 'wells', 'won', 'four', 'text', 'card', 'tisdale', 'fwd', 'appreciate', 'non', 'experience', 'savings', 'settlements', 'draft', 'couple', 'informed', 'biz', 'watch', 'plus', 'sun', 'expense', 'images', 'land', 'occur', 'flowing', 'mar', 'terry', 'darren', 'cheap', 'weight', 'dynegy', 'activities', 'become', 'mr', 'format', 'attention', 'entire', 'photoshop', 'williams', 'instructions', 'neon', 'janet', 'contains', 'ago', 'friends', 'against', 'boas', 'music', 'certain', 'liz', 'svcs', 'record', 'fast', 'dave', 'held', 'mind', 'ua', 'publication', 'differ', 'comments', 'fun', 'rest', 'instant', 'agent', 'communications', 'director', 'partners', 'investors', 'expedia', 'kevin', 'assist', 'safe', 'approval', 'allocate', 'black', 'none', 'intrastate', 'document', 'eric', 'hakemack', 'expired', 'lower', 'active', 'secure', 'cc', 'five', 'determine', 'press', 'colspan', 'missing', 'jill', 'discussion', 'relief', 'respect', 'specific', 'technologies', 'al', 'holmes', 'white', 'yesterday', 'medical', 'pinion', 'sorry', 'men', 'leave', 'pass', 'video', 'gomes', 'doctor', 'projects', 'limit', 'air', 'knle', 'pharmacy', 'confirmation', 'opportunity', 'involve', 'notify', 'gtc', 'class', 'ken', 'started', 'outage', 'confidential', 'room', 'blue', 'estimated', 'officer', 'reach', 'messages', 'database', 'words', 'prc', 'tracked', 'transition', 'light', 'national', 'hot', 'offering', 'gulf', 'provides', 'iit', 'demokritos', 'mckay', 'average', 'wide', 'heard', 'files', 'dan', 'billed', 'mccoy', 'rc', 'exactly', 'middle', 'select', 'bruce', 'louisiana', 'receiving', 'california', 'event', 'roll', 'mops', 'william', 'appear', 'perfect', 'html', 'features', 'join', 'greater', 'sunday', 'pick', 'featured', 'cdnow', 'prize', 'reveffo', 'olsen', 'expects', 'estimate', 'near', 'common', 'package', 'title', 'whether', 'bought', 'evergreen', 'difference', 'elizabeth', 'history', 'monitor', 'advised', 'result', 'sources', 'school', 'unaccounted', 'paragraph', 'turn', 'kimberly', 'increased', 'communication', 'members', 'concerns', 'uncertainties', 'associated', 'reduce', 'committed', 'wi', 'asap', 'goes', 'trader', 'waiting', 'canada', 'worth', 'representative', 'claim', 'ceo', 'london', 'discussions', 'php', 'brazos', 'trevino', 'calling', 'involved', 'la', 'gift', 'southern', 'groups', 'hour', 'tufco', 'previously', 'voice', 'normally', 'resolve', 'efforts', 'nor', 'recent', 'purchasing', 'county', 'ok', 'express', 'generic', 'according', 'respond', 'situation', 'hold', 'lot', 'interconnect', 'word', 'came', 'west', 'role', 'opportunities', 'corporate', 'remain', 'similar', 'readers', 'suggestions', 'subscribers', 'projections', 'lead', 'learn', 'resolved', 'agreed', 'sec', 'head', 'enjoy', 'img', 'rnd', 'responsible', 'outstanding', 'member', 'panenergy', 'american', 'cass', 'register', 'promotions', 'parties', 'winfree', 'selling', 'usage', 'appropriate', 'assignment', 'media', 'believes', 'require', 'submit', 'model', 'spinnaker', 'copano', 'facilities', 'opinion', 'factors', 'identified', 'beverly', 'ews', 'gdp', 'deliver', 'job', 'profile', 'across', 'neuweiler', 'suggest', 'girls', 'manage', 'usa', 'local', 'bad', 'greg', 'vs', 'fees', 'digital', 'cf', 'strangers', 'registration', 'delta', 'rolex', 'goliad', 'hesco', 'success', 'primary', 'quarter', 'course', 'chairman', 'petroleum', 'notes', 'medications', 'ei', 'instead', 'fine', 'lake', 'pre', 'force', 'seek', 'recipient', 'gain', 'placed', 'age', 'least', 'body', 'asking', 'discussed', 'hanson', 'emails', 'nominate', 'ext', 'known', 'ones', 'ed', 'assigned', 'htmlimg', 'means', 'present', 'various', 'invoices', 'gd', 'agency', 'along', 'located', 'reflects', 'solutions', 'ex', 'house', 'cds', 'br', 'owner', 'apr', 'sullivan', 'basin', 'linda', 'worked', 'car', 'seen', 'properties', 'booked', 'higher', 'store', 'est', 'revenue', 'wait', 'women', 'far', 'met', 'wholesale', 'range', 'kcs', 'recorded', 'brown', 'lots', 'match', 'input', 'grant', 'providing', 'huge', 'investor', 'kelly', 'apply', 'paths', 'handling', 'pipes', 'advantage', 'analysis', 'focus', 'draw', 'red', 'origination', 'connection', 'planning', 'wilson', 'golf', 'summary', 'item', 'bankruptcy', 'expenses', 'pgev', 'encina', 'beaty', 'memo', 'initial', 'thousand', 'mills', 'penis', 'friend', 'conversation', 'multiple', 'martin', 'names', 'bit', 'dth', 'talked', 'behalf', 'preliminary', 'button', 'herein', 'gisb', 'coupon', 'sa', 'oi', 'appears', 'door', 'texaco', 'csikos', 'arrangements', 'cpr', 'expires', 'popular', 'sending', 'research', 'conditions', 'gb', 'board', 'ca', 'applications', 'tried', 'paying', 'acquisition', 'reporting', 'normal', 'maintenance', 'resume', 'announced', 'attachment', 'buyer', 'objectives', 'prod', 'represent', 'sandi', 'hplnol', 'government', 'committee', 'running', 'tetco', 'discount', 'jo', 'holding', 'earlier', 'positions', 'happen', 'mailing', 'decided', 'recently', 'chris', 'xanax', 'valium', 'broadband', 'individual', 'station', 'td', 'financing', 'somehow', 'pena', 'critical', 'attend', 'kristen', 'inform', 'highly', 'hl', 'phillips', 'minutes', 'titles', 'affiliate', 'wife', 'lonestar', 'charlotte', 'quickly', 'paper', 'test', 'comes', 'mobile', 'internal', 'privacy', 'ideas', 'live', 'gotten', 'floor', 'benefit', 'percent', 'ms', 'dr', 'ebs', 'msn', 'gave', 'dallas', 'enterprise', 'rx', 'spring', 'ftar', 'ooking', 'hawkins', 'exclusive', 'selected', 'baxter', 'actually', 'single', 'shop', 'nominates', 'guarantee', 'minute', 'correctly', 'unique', 'bid', 'building', 'stated', 'accept', 'assumptions', 'centana', 'senior', 'pill', 'kinsey', 'sap', 'immediate', 'goals', 'category', 'mitchell', 'acceptance', 'termination', 'sweeney', 'facts', 'amazon', 'arrangement', 'josey', 'funds', 'among', 'accuracy', 'mean', 'rather', 'kim', 'egmnom', 'indicate', 'updates', 'extra', 'adjustment', 'accounts', 'lowest', 'gold', 'purposes', 'remaining', 'talking', 'entry', 'road', 'load', 'simply', 'europe', 'lindley', 'understood', 'logos', 'hi', 'speed', 'profit', 'notified', 'jackson', 'z', 'vols', 'serve', 'additionally', 'shipped', 'connor', 'fontfont', 'q', 'kept', 'dollar', 'jr', 'almost', 'fri', 'paul', 'documents', 'analyst', 'crude', 'cap', 'shopping', 'aug', 'clearance', 'schneider', 'ftworth', 'father', 'anticipated', 'resellers', 'congress', 'counterparties', 'epgt', 'buying', 'san', 'invest', 'cartwheel', 'brandywine', 'wrong', 'mtbe', 'split', 'submitted', 'hull', 'gra', 'children', 'leader', 'true', 'baseload', 'mb', 'letters', 'billion', 'rights', 'mtr', 'heidi', 'clean', 'historical', 'asset', 'foreign', 'gr', 'entity', 'developed', 'maybe', 'jeffrey', 'transmission', 'outside', 'lost', 'membership', 'invitation', 'ocean', 'legislation', 'hernandez', 'pep', 'payments', 'wallis', 'rev', 'kenneth', 'seaman', 'annual', 'guess', 'bammel', 'lines', 'guadalupe', 'zivley', 'exception', 'example', 'pathing', 'revisions', 'pipelines', 'equity', 'budget', 'wed', 'dealers', 'window', 'juno', 'claims', 'bottom', 'standard', 'alternative', 'merchant', 'braband', 'topica', 'telephone', 'reliant', 'speculative', 'yes', 'en', 'morgan', 'cable', 'edmondson', 'participate', 'usb', 'throughout', 'checked', 'myself', 'contents', 'fat', 'investments', 'six', 'build', 'giving', 'calendar', 'inherent', 'edition', 'darial', 'hr', 'trip', 'pull', 'moving', 'concern', 'proposed', 'rm', 'deer', 'enquiries', 'alt', 'tammy', 'front', 'reduction', 'evening', 'concerning', 'gets', 'effect', 'isn', 'haven', 'cowboy', 'sea', 'dvd', 'launch', 'minimum', 'changing', 'built', 'avoid', 'chief', 'stephen', 'chad', 'manual', 'finally', 'strategy', 'executive', 'thousands', 'conflict', 'resulting', 'policy', 'commission', 'stand', 'positive', 'quantity', 'programs', 'airmail', 'texoma', 'prepared', 'austin', 'matt', 'intent', 'uae', 'citibank', 'jaquet', 'hol', 'harris', 'min', 'hplr', 'advance', 'weather', 'terminated', 'whom', 'sheet', 'venturatos', 'cellpadding', 'hotel', 'leading', 'guaranteed', 'idea', 'announce', 'pleased', 'award', 'operational', 'prepare', 'schedulers', 'child', 'sum', 'quote', 'adjusted', 'warning', 'issued', 'ga', 'cross', 'detail', 'pertaining', 'tess', 'owe', 'crow', 'availabilities', 'griffin', 'christy', 'crosstex', 'eel', 'itoy', 'heart', 'licensed', 'overnight', 'cal', 'otherwise', 'luck', 'stretch', 'generation', 'broker', 'construed', 'except', 'traders', 'carry', 'column', 'approx', 'main', 'alert', 'charges', 'step', 'revenues', 'games', 'gottlob', 'looked', 'individuals', 'beck', 'stuff', 'welcome', 'port', 'glover', 'description', 'daniel', 'quantities', 'park', 'managing', 'town', 'seller', 'summer', 'tina', 'dates', 'eff', 'dudley', 'ferc', 'robin', 'charles', 'customerservice', 'zonedubai', 'emirates', 'aeor', 'clickathome', 'materia', 'island', 'vaughn', 'sexual', 'eiben', 'forms', 'delete', 'realize', 'tailgate', 'behind', 'villarreal', 'lon', 'benoit', 'simple', 'tech', 'ahead', 'double', 'ordering', 'se', 'miss', 'law', 'eb', 'post', 'outlook', 'equipment', 'leslie', 'reeves', 'org', 'tools', 'cold', 'adjustments', 'contained', 'saw', 'edit', 'deciding', 'finance', 'patti', 'listbot', 'river', 'kathryn', 'holiday', 'successful', 'unable', 'advisor', 'pool', 'bryce', 'outages', 'adjust', 'screen', 'otc', 'brent', 'helps', 'auto', 'foot', 'region', 'links', 'contain', 'knowledge', 'yvette', 'dial', 'pressure', 'detailed', 'indicated', 'charged', 'sites', 'makes', 'female', 'mcmills', 'cook', 'mazowita', 'meredith', 'allocations', 'meetings', 'particular', 'environment', 'drug', 'search', 'mailings', 'designed', 'rock', 'measurement', 'art', 'corrected', 'kids', 'benefits', 'tv', 'seems', 'husband', 'fix', 'grow', 'decision', 'wireless', 'mo', 'conference', 'interview', 'levels', 'copies', 'cindy', 'urgent', 'regular', 'payroll', 'shown', 'consumers', 'reliable', 'tr', 'indicating', 'coast', 'greif', 'severson', 'tri', 'vicodin', 'liquids', 'significant', 'intend', 'usd', 'pager', 'avails', 'spencer', 'ce', 'charset', 'verdana', 'fully', 'flynn', 'da', 'personnel', 'multi', 'closed', 'vice', 'administration', 'gmt', 'midstream', 'eye', 'speckels', 'studio', 'cilco', 'likely', 'managers', 'structure', 'sit', 'parent', 'preparation', 'mix', 'mmbtus', 'timing', 'happening', 'lottery', 'killing', 'acquire', 'mack', 'pcx', 'fares', 'internationa', 'notification', 'swift', 'identify', 'areas', 'separate', 'unless', 'producers', 'allows', 'pretty', 'waste', 'joanie', 'drop', 'taxes', 'premium', 'teams', 'choice', 'largest', 'addressed', 'dolphin', 'ngo', 'self', 'davis', 'htm', 'ad', 'graphics', 'hit', 'competitive', 'thus', 'incorrect', 'ti', 'acts', 'previous', 'edu', 'proven', 'electric', 'pictures', 'charlene', 'benedict', 'chevron', 'treatment', 'lesson', 'player', 'sds', 'wc', 'intraday', 'assurance', 'sdsnom', 'rebecca', 'quit', 'netco', 'intra', 'whatever', 'lyondell', 'reviewed', 'solicitation', 'filings', 'log', 'noon', 'locations', 'joe', 'completely', 'rivers', 'language', 'street', 'automatically', 'ft', 'powerful', 'specials', 'alone', 'fyi', 'properly', 'proper', 'explode', 'decrease', 'medication', 'desks', 'impacted', 'anywhere', 'completion', 'banking', 'consider', 'certificate', 'exercise', 'zeroed', 'websites', 'tonight', 'diligence', 'education', 'club', 'vegas', 'affordable', 'sports', 'predictions', 'billing', 'diamond', 'posted', 'prayer', 'actions', 'nomad', 'resuits', 'jason', 'purpose', 'deposit', 'entertainment', 'materially', 'blank', 'resolution', 'anderson', 'nat', 'rom', 'soma', 'organization', 'aquila', 'solid', 'affected', 'transco', 'spend', 'responsibilities', 'assume', 'header', 'accountant', 'functionality', 'meant', 'killed', 'analysts', 'rick', 'rolled', 'noted', 'discovered', 'offices', 'torch', 'often', 'york', 'joint', 'briley', 'competition', 'guide', 'intercompany', 'son', 'settlement', 'presently', 'cart', 'tim', 'entries', 'russ', 'valadez', 'rules', 'molly', 'apple', 'atleast', 'scheduler', 'pi', 'hector', 'dell', 'opm', 'hottlist', 'yap', 'gone', 'heal', 'llc', 'setting', 'reached', 'proposal', 'hundred', 'trust', 'official', 'table', 'mcgee', 'written', 'operation', 'cellspacing', 'laptop', 'feature', 'ram', 'victoria', 'larry', 'units', 'requests', 'continued', 'external', 'pack', 'couldn', 'lateral', 'strictly', 'resource', 'although', 'sr', 'commodity', 'pulled', 'protocol', 'bed', 'generated', 'redmond', 'girl', 'apparently', 'tool', 'reviews', 'released', 'movies', 'inside', 'shareholder', 'rr', 'compensation', 'beliefs', 'foresee', 'lease', 'rule', 'marta', 'chemical', 'hillary', 'hp', 'tongue', 'adonis', 'advises', 'master', 'eight', 'wasn', 'itself', 'documentation', 'xl', 'humble', 'elsa', 'pics', 'hughes', 'brokered', 'distribute', 'consultation', 'sheri', 'lists', 'cannon', 'treated', 'factor', 'putting', 'verified', 'releases', 'enhanced', 'controls', 'craig', 'worksheet', 'conversion', 'max', 'hrs', 'helpful', 'hand', 'producing', 'dl', 'developing', 'design', 'woman', 'understands', 'standards', 'promotion', 'sarco', 'hospital', 'ffffff', 'respective', 'richmond', 'conoco', 'driver', 'easily', 'sean', 'den', 'gateway', 'holdings', 'brad', 'college', 'gains', 'adult', 'dated', 'em', 'mcloughlin', 'anticipates', 'henderson', 'julia', 'negotiations', 'sofftwaares', 'garrick', 'comstock', 'trochta', 'imceanotes', 'ecom', 'larger', 'nommensen', 'coordinate', 'partnership', 'otcbb', 'announces', 'louis', 'dealer', 'reliance', 'season', 'agua', 'dulce', 'offshore', 'gathered', 'forever', 'function', 'happened', 'sample', 'easier', 'aim', 'pa', 'expensive', 'thinks', 'maximum', 'war', 'mining', 'drilling', 'owned', 'todd', 'advanced', 'provider', 'pending', 'providers', 'silver', 'cherry', 'hundreds', 'thoughts', 'addresses', 'beach', 'baby', 'requires', 'caused', 'variance', 'extension', 'carbide', 'anytime', 'adding', 'triple', 'dawn', 'martinez', 'entering', 'login', 'bretz', 'ls', 'writeoff', 'locker', 'wiil', 'block', 'blood', 'romeo', 'responsibility', 'brennan', 'btu', 'venture', 'connected', 'nascar', 'opinions', 'executed', 'cell', 'flag', 'doctors', 'invoiced', 'marlin', 'coffey', 'nice', 'amazing', 'ii', 'determined', 'handled', 'keeping', 'touch', 'upgrade', 'shipment', 'brought', 'forwarding', 'confidence', 'hesitate', 'seem', 'electronic', 'appreciated', 'deadline', 'franklin', 'heather', 'reasons', 'passed', 'safety', 'procedures', 'payback', 'networks', 'utility', 'count', 'africa', 'exact', 'creating', 'loading', 'processed', 'court', 'tier', 'sender', 'att', 'mailbox', 'glad', 'buddy', 'profiles', 'portion', 'protection', 'compressor', 'okay', 'oba', 'finding', 'heads', 'bar', 'turned', 'remote', 'illustrator', 'oem', 'noticed', 'mails', 'darron', 'nick', 'urbanek', 'jerry', 'barrett', 'ehronline', 'und', 'abdv', 'egm', 'couid', 'technoiogies', 'owns', 'improved', 'eat', 'moment', 'owners', 'develop', 'installed', 'videos', 'frank', 'hearing', 'inches', 'busy', 'ref', 'valuable', 'et', 'un', 'url', 'shawna', 'iso', 'capture', 'extremely', 'ya', 'causing', 'consent', 'anyway', 'round', 'discrepancies', 'cheapest', 'confidentiality', 'disclosure', 'prohibited', 'vol', 'correction', 'communicate', 'processes', 'spain', 'shareholders', 'supported', 'smoking', 'mine', 'biggest', 'erections', 'platform', 'miles', 'exciting', 'association', 'die', 'restricted', 'ma', 'income', 'goal', 'bane', 'collection', 'nathan', 'wind', 'piece', 'familiar', 'gore', 'experiencing', 'pico', 'mai', 'dewpoint', 'tessie', 'hair', 'bussell', 'diane', 'delivering', 'originally', 'accurate', 'began', 'seven', 'tracking', 'randall', 'gay', 'emerging', 'prescriptions', 'story', 'arial', 'florida', 'space', 'ownership', 'european', 'sutton', 'concerned', 'male', 'spent', 'agreements', 'industries', 'picture', 'filled', 'continues', 'death', 'choate', 'majeure', 'device', 'hence', 'ten', 'campaign', 'massive', 'eyes', 'requesting', 'lives', 'reminder', 'eliminate', 'copied', 'consemiu', 'died', 'sound', 'offered', 'expressed', 'anti', 'duplicate', 'steps', 'books', 'improve', 'implementation', 'gives', 'ac', 'peggy', 'proprietary', 'ways', 'advertisement', 'published', 'earnings', 'mortgage', 'consumer', 'ct', 'tape', 'fl', 'cia', 'organizational', 'agenda', 'rental', 'carriere', 'moshou', 'church', 'trouble', 'medium', 'aggressive', 'smart', 'zajac', 'ail', 'participants', 'gap', 'earthlink', 'wire', 'trades', 'messaging', 'ut', 'wil', 'richardson', 'blvd', 'glo', 'seneca', 'pubiisher', 'imited', 'isc', 'contacts', 'sleep', 'kyle', 'cooperation', 'possibly', 'leaving', 'motor', 'hopefully', 'tie', 'speak', 'mi', 'suggested', 'canadian', 'uses', 'connect', 'pvr', 'rich', 'places', 'auction', 'po', 'spacer', 'client', 'recommended', 'royalty', 'amended', 'default', 'living', 'regardless', 'human', 'bringing', 'focused', 'stores', 'variety', 'netherlands', 'leaders', 'bowen', 'salary', 'signed', 'penny', 'loan', 'desktop', 'chase', 'pleasure', 'compare', 'session', 'overall', 'stranger', 'length', 'planned', 'sp', 'darrel', 'raise', 'palestinian', 'expiration', 'serial', 'premiere', 'suzanne', 'reduced', 'players', 'applicable', 'impotence', 'buckley', 'wayne', 'hansen', 'indicative', 'sabrae', 'dating', 'winners', 'marshall', 'highest', 'ea', 'presentation', 'allowed', 'square', 'danny', 'gepl', 'hydrocarbon', 'alpine', 'christmas', 'muscle', 'souza', 'relating', 'begins', 'ecf', 'forth', 'answers', 'audit', 'approve', 'lunch', 'types', 'starts', 'difficult', 'le', 'lasts', 'series', 'till', 'edge', 'growing', 'covered', 'shipper', 'sometime', 'republic', 'filter', 'sooner', 'increasing', 'nelson', 'percentage', 'returned', 'pop', 'interface', 'kin', 'experienced', 'prime', 'merger', 'obtain', 'ryan', 'servers', 'attachments', 'achieve', 'effects', 'gov', 'examples', 'procedure', 'explore', 'caribbean', 'rally', 'amounts', 'comfort', 'attempt', 'greatly', 'amelia', 'engel', 'delay', 'fare', 'der', 'cove', 'filing', 'fletcher', 'leth', 'undervalued', 'cents', 'esther', 'hlavaty', 'reid', 'lls', 'troy', 'palmer', 'metals', 'las', 'carter', 'luis', 'migration', 'brief', 'hess', 'therein', 'ur', 'pond', 'joanne', 'community', 'tglo', 'eogi', 'ml', 'wysak', 'felipe', 'errors', 'affect', 'convenient', 'minimal', 'boost', 'incremental', 'decide', 'reserve', 'superior', 'kerr', 'willing', 'quite', 'wild', 'unlimited', 'sans', 'mother', 'computers', 'unfortunately', 'ordered', 'satisfaction', 'priority', 'traded', 'testing', 'portal', 'ward', 'lets', 'aren', 'knows', 'refer', 'shot', 'fda', 'tue', 'saying', 'cancel', 'forecast', 'cousino', 'bass', 'permanent', 'phones', 'technical', 'whose', 'objective', 'cards', 'distributed', 'learning', 'fire', 'drill', 'towards', 'forget', 'explosion', 'gloria', 'formula', 'redelivery', 'audio', 'visual', 'encoding', 'approach', 'doubt', 'staffing', 'excite', 'corel', 'tm', 'enronavailso', 'contacting', 'alland', 'heavy', 'economic', 'nigeria', 'milwaukee', 'phillip', 'curve', 'returns', 'padre', 'kathy', 'buttons', 'sir', 'vary', 'sounds', 'disclose', 'authority', 'flw', 'straight', 'worldnet', 'beemer', 'ooo', 'defs', 'thorough', 'officers', 'flight', 'prefer', 'awesome', 'macintosh', 'feet', 'constitutes', 'formosa', 'porn', 'armstrong', 'driscoll', 'watches', 'newsietter', 'twenty', 'tommy', 'fields', 'method', 'setup', 'allocating', 'initially', 'missed', 'clarification', 'especially', 'dorcheus', 'del', 'millions', 'insurance', 'pooling', 'trial', 'tennessee', 'ellis', 'direction', 'bold', 'catch', 'performing', 'accepted', 'matters', 'batch', 'continuing', 'winning', 'symbol', 'offsystem', 'decisions', 'produced', 'ended', 'greatest', 'degree', 'solmonson', 'imbalances', 'fall', 'fear', 'hate', 'fight', 'reallocated', 'debt', 'reform', 'australia', 'plain', 'prompt', 'remains', 'ifhsc', 'enhancements', 'connevey', 'jay', 'valued', 'lay', 'infrastructure', 'military', 'allowing', 'ff', 'dry', 'Prediction']\n",
      "\n",
      "📊 First 3 rows of your dataset:\n",
      "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
      "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
      "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
      "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
      "\n",
      "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0       0    0               0         0         0   0    0           0  \n",
      "1       0    0               0         0         0   1    0           0  \n",
      "2       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[3 rows x 3002 columns]\n",
      "🎯 Found matching columns: 'email' (text) and 'spam' (labels)\n",
      "🏷️ Unique labels found: [0 1 2 4 5 3]\n",
      "\n",
      "📈 Final dataset statistics:\n",
      "   Total emails: 5172\n",
      "   Spam emails: 92\n",
      "   Ham emails: 5080\n",
      "   Balance ratio: 1.78% spam\n",
      "\n",
      "Dataset loaded successfully!\n",
      "Total emails: 5172\n",
      "Spam emails: 92\n",
      "Ham emails: 5080\n",
      "\n",
      "==================================================\n",
      "DATA EXPLORATION\n",
      "==================================================\n",
      "Dataset shape: (5172, 2)\n",
      "Missing values: 0\n",
      "Class distribution:\n",
      "label\n",
      "0    5104\n",
      "1      57\n",
      "2       5\n",
      "4       3\n",
      "5       2\n",
      "3       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average email length:\n",
      "Spam: 1.0 characters\n",
      "Ham: 1.0 characters\n",
      "\n",
      "==================================================\n",
      "FEATURE ENGINEERING\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 315\u001b[0m\n\u001b[0;32m    312\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# Split the data\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m X_text_train, X_text_test, X_num_train, X_num_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m    316\u001b[0m     X_text, X_numeric, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m    317\u001b[0m )\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_text_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_text_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:2940\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2936\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2938\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2940\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2942\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2945\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2946\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2947\u001b[0m     )\n\u001b[0;32m   2948\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:1927\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1898\u001b[0m \n\u001b[0;32m   1899\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1926\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1927\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1928\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:2342\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2340\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 2342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2346\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2347\u001b[0m     )\n\u001b[0;32m   2349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[0;32m   2350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2351\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2352\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2353\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "# Email Spam Classification with Large Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Email Spam Classification with Large Dataset\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# STEP 1: Load Dataset\n",
    "def load_kaggle_dataset(file_path):\n",
    "    \"\"\"Load emails.csv dataset with enhanced error handling\"\"\"\n",
    "    try:\n",
    "        print(f\"Attempting to load: {file_path}\")\n",
    "        \n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"✅ File loaded successfully! Shape: {df.shape}\")\n",
    "        print(\"📋 Columns found:\", df.columns.tolist())\n",
    "        \n",
    "        # Show first few rows to understand structure\n",
    "        print(\"\\n📊 First 3 rows of your dataset:\")\n",
    "        print(df.head(3))\n",
    "        \n",
    "        # Common column name patterns for spam datasets\n",
    "        column_mappings = [\n",
    "            ('text', 'label'),\n",
    "            ('message', 'label'), \n",
    "            ('email', 'spam'),\n",
    "            ('Message', 'Category'),\n",
    "            ('v2', 'v1'),  # SMS spam dataset format\n",
    "            ('text', 'target'),\n",
    "            ('content', 'class'),\n",
    "            ('body', 'type'),\n",
    "            ('email_text', 'is_spam'),\n",
    "            ('content', 'label'),\n",
    "            ('text', 'class')\n",
    "        ]\n",
    "        \n",
    "        # Try to find the right columns automatically\n",
    "        for text_col, label_col in column_mappings:\n",
    "            if text_col in df.columns and label_col in df.columns:\n",
    "                print(f\"🎯 Found matching columns: '{text_col}' (text) and '{label_col}' (labels)\")\n",
    "                \n",
    "                # Create standardized dataframe\n",
    "                result_df = df[[text_col, label_col]].copy()\n",
    "                result_df.columns = ['text', 'label']\n",
    "                \n",
    "                # Remove any missing values\n",
    "                initial_size = len(result_df)\n",
    "                result_df = result_df.dropna()\n",
    "                if len(result_df) < initial_size:\n",
    "                    print(f\"⚠️ Removed {initial_size - len(result_df)} rows with missing values\")\n",
    "                \n",
    "                # Ensure text column is string type\n",
    "                result_df['text'] = result_df['text'].astype(str)\n",
    "                \n",
    "                # Show label distribution\n",
    "                unique_labels = result_df['label'].unique()\n",
    "                print(f\"🏷️ Unique labels found: {unique_labels}\")\n",
    "                \n",
    "                # Convert labels to 0/1 format\n",
    "                if len(unique_labels) == 2:\n",
    "                    if result_df['label'].dtype == 'object':\n",
    "                        # Try different spam indicators\n",
    "                        spam_indicators = ['spam', 'SPAM', 'Spam', '1', 1, 'positive', 'yes', 'Y']\n",
    "                        ham_indicators = ['ham', 'HAM', 'Ham', '0', 0, 'negative', 'no', 'N']\n",
    "                        \n",
    "                        converted = False\n",
    "                        for spam_word in spam_indicators:\n",
    "                            if spam_word in unique_labels:\n",
    "                                result_df['label'] = (result_df['label'] == spam_word).astype(int)\n",
    "                                print(f\"✅ Converted '{spam_word}' → 1 (spam), others → 0 (ham)\")\n",
    "                                converted = True\n",
    "                                break\n",
    "                        \n",
    "                        if not converted:\n",
    "                            # If no standard labels found, convert first unique value to 1\n",
    "                            first_label = unique_labels[0]\n",
    "                            result_df['label'] = (result_df['label'] == first_label).astype(int)\n",
    "                            print(f\"⚠️ Auto-converted '{first_label}' → 1, others → 0\")\n",
    "                            print(\"⚠️ Please verify this conversion is correct!\")\n",
    "                \n",
    "                # Final validation\n",
    "                spam_count = sum(result_df['label'])\n",
    "                ham_count = len(result_df) - spam_count\n",
    "                \n",
    "                print(f\"\\n📈 Final dataset statistics:\")\n",
    "                print(f\"   Total emails: {len(result_df)}\")\n",
    "                print(f\"   Spam emails: {spam_count}\")\n",
    "                print(f\"   Ham emails: {ham_count}\")\n",
    "                print(f\"   Balance ratio: {spam_count/len(result_df):.2%} spam\")\n",
    "                \n",
    "                if spam_count == 0 or ham_count == 0:\n",
    "                    print(\"⚠️ WARNING: Only one class found! Check your labels.\")\n",
    "                \n",
    "                return result_df\n",
    "        \n",
    "        # If no automatic match found, provide manual guidance\n",
    "        print(\"\\n❌ Could not automatically detect text and label columns.\")\n",
    "        print(\"\\n📋 Your dataset columns:\")\n",
    "        for i, col in enumerate(df.columns):\n",
    "            sample_values = df[col].dropna().head(3).tolist()\n",
    "            print(f\"   {i+1}. '{col}' - Sample: {sample_values}\")\n",
    "        \n",
    "        print(f\"\\n🔧 Manual fix needed:\")\n",
    "        print(f\"   1. Identify which column contains the email text\")\n",
    "        print(f\"   2. Identify which column contains spam/ham labels\")\n",
    "        print(f\"   3. Update the code:\")\n",
    "        print(f\"      df = pd.read_csv('emails.csv')\")\n",
    "        print(f\"      df = df[['your_text_column', 'your_label_column']]\")\n",
    "        print(f\"      df.columns = ['text', 'label']\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ File '{file_path}' not found!\")\n",
    "        print(\"📁 Make sure 'emails.csv' is in your current working directory.\")\n",
    "        \n",
    "        # Show current directory and available files\n",
    "        import os\n",
    "        print(f\"📂 Current directory: {os.getcwd()}\")\n",
    "        try:\n",
    "            csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "            if csv_files:\n",
    "                print(f\"📄 CSV files found: {csv_files}\")\n",
    "            else:\n",
    "                print(\"📄 No CSV files found in current directory\")\n",
    "        except:\n",
    "            print(\"❌ Could not list directory contents\")\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"❌ File '{file_path}' is empty!\")\n",
    "        return None\n",
    "        \n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"❌ Error parsing CSV file: {e}\")\n",
    "        print(\"💡 Try opening the file in a text editor to check its format\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error loading dataset: {e}\")\n",
    "        print(f\"💡 Error type: {type(e).__name__}\")\n",
    "        return None\n",
    "\n",
    "# STEP 2: Create Sample Large Dataset (if you don't have one yet)\n",
    "def create_sample_large_dataset():\n",
    "    \"\"\"Create a larger sample dataset for demonstration\"\"\"\n",
    "    \n",
    "    # Spam email templates\n",
    "    spam_templates = [\n",
    "        \"FREE money! Click here to win ${}! Limited time offer!\",\n",
    "        \"URGENT: Your account will be closed! Click link immediately!\",\n",
    "        \"Congratulations! You've won {}! Send us your details!\",\n",
    "        \"Buy cheap {} online! No prescription needed!\",\n",
    "        \"SALE! {}% discount on everything! Buy now!\",\n",
    "        \"Make ${} from home! Easy work!\",\n",
    "        \"Lose {} pounds in 30 days! Guaranteed!\",\n",
    "        \"HOT singles in your area! Click now!\",\n",
    "        \"Your loan of ${} has been approved! Claim now!\",\n",
    "        \"BREAKING: Celebrity secret revealed! Click here!\"\n",
    "    ]\n",
    "    \n",
    "    # Ham email templates\n",
    "    ham_templates = [\n",
    "        \"Hi {}, let's meet for coffee tomorrow at {} PM\",\n",
    "        \"Your order #{} has been shipped and will arrive by {}\",\n",
    "        \"Team meeting scheduled for {} at {} AM in conference room\",\n",
    "        \"Thanks for your presentation on {}, it was very informative\",\n",
    "        \"Please review the attached {} document and provide feedback\",\n",
    "        \"Your flight ticket confirmation for {} trip\",\n",
    "        \"Happy {}! Hope you have a wonderful day\",\n",
    "        \"The {} project deadline has been extended to next {}\",\n",
    "        \"Reminder: Your appointment with {} is tomorrow at {}\",\n",
    "        \"Invoice #{} for {} services is attached\"\n",
    "    ]\n",
    "    \n",
    "    emails = []\n",
    "    labels = []\n",
    "    \n",
    "    # Generate 2500 emails of each type\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate spam emails\n",
    "    for i in range(2500):\n",
    "        template = np.random.choice(spam_templates)\n",
    "        if '{}' in template:\n",
    "            if 'money' in template or 'win' in template or 'loan' in template:\n",
    "                email = template.format(np.random.randint(1000, 10000))\n",
    "            elif 'discount' in template or 'pounds' in template:\n",
    "                email = template.format(np.random.randint(10, 90))\n",
    "            elif 'won' in template:\n",
    "                prizes = ['iPhone', 'car', 'vacation', 'laptop', 'TV']\n",
    "                email = template.format(np.random.choice(prizes))\n",
    "            elif 'cheap' in template:\n",
    "                products = ['medications', 'watches', 'electronics', 'supplements']\n",
    "                email = template.format(np.random.choice(products))\n",
    "            else:\n",
    "                email = template\n",
    "        else:\n",
    "            email = template\n",
    "        \n",
    "        emails.append(email)\n",
    "        labels.append(1)\n",
    "    \n",
    "    # Generate ham emails\n",
    "    names = ['John', 'Sarah', 'Mike', 'Lisa', 'David', 'Emma', 'Chris', 'Anna']\n",
    "    times = ['9', '10', '11', '2', '3', '4']\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "    months = ['January', 'February', 'March', 'April', 'May', 'June']\n",
    "    projects = ['marketing', 'development', 'research', 'design', 'sales']\n",
    "    \n",
    "    for i in range(2500):\n",
    "        template = np.random.choice(ham_templates)\n",
    "        if '{}' in template:\n",
    "            if 'meet' in template:\n",
    "                email = template.format(np.random.choice(names), np.random.choice(times))\n",
    "            elif 'order' in template:\n",
    "                email = template.format(np.random.randint(1000, 9999), np.random.choice(days))\n",
    "            elif 'meeting' in template:\n",
    "                email = template.format(np.random.choice(days), np.random.choice(times))\n",
    "            elif 'presentation' in template:\n",
    "                email = template.format(np.random.choice(projects))\n",
    "            elif 'document' in template:\n",
    "                docs = ['contract', 'report', 'proposal', 'budget', 'plan']\n",
    "                email = template.format(np.random.choice(docs))\n",
    "            elif 'flight' in template:\n",
    "                email = template.format(np.random.choice(months))\n",
    "            elif 'Happy' in template:\n",
    "                events = ['birthday', 'anniversary', 'new year', 'holiday']\n",
    "                email = template.format(np.random.choice(events))\n",
    "            elif 'project' in template:\n",
    "                email = template.format(np.random.choice(projects), np.random.choice(months))\n",
    "            elif 'appointment' in template:\n",
    "                email = template.format(np.random.choice(names), np.random.choice(times))\n",
    "            elif 'Invoice' in template:\n",
    "                services = ['consulting', 'design', 'development', 'marketing']\n",
    "                email = template.format(np.random.randint(1000, 9999), np.random.choice(services))\n",
    "            else:\n",
    "                email = template\n",
    "        else:\n",
    "            email = template\n",
    "            \n",
    "        emails.append(email)\n",
    "        labels.append(0)\n",
    "    \n",
    "    df = pd.DataFrame({'text': emails, 'label': labels})\n",
    "    df['text'] = df['text'].astype(str)  # Ensure text column is string type\n",
    "    return df\n",
    "\n",
    "# Load or create dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = load_kaggle_dataset('emails.csv')\n",
    "\n",
    "# If loading fails, create a sample dataset\n",
    "if df is None:\n",
    "    print(\"\\nCreating sample dataset...\")\n",
    "    df = create_sample_large_dataset()\n",
    "    print(\"✅ Sample dataset created with 5000 emails (2500 spam, 2500 ham)\")\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"\\nDataset loaded successfully!\")\n",
    "    print(f\"Total emails: {len(df)}\")\n",
    "    print(f\"Spam emails: {sum(df['label'])}\")\n",
    "    print(f\"Ham emails: {len(df) - sum(df['label'])}\")\n",
    "    \n",
    "    # STEP 3: Data Exploration\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATA EXPLORATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "    \n",
    "    # Text length analysis\n",
    "    df['text_length'] = df['text'].str.len()\n",
    "    print(f\"\\nAverage email length:\")\n",
    "    print(f\"Spam: {df[df['label']==1]['text_length'].mean():.1f} characters\")\n",
    "    print(f\"Ham: {df[df['label']==0]['text_length'].mean():.1f} characters\")\n",
    "    \n",
    "    # STEP 4: Data Preprocessing and Feature Engineering\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FEATURE ENGINEERING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Add more features\n",
    "    df['word_count'] = df['text'].str.split().str.len()\n",
    "    df['exclamation_count'] = df['text'].str.count('!')\n",
    "    df['question_count'] = df['text'].str.count('\\?')\n",
    "    df['uppercase_ratio'] = df['text'].str.count(r'[A-Z]') / df['text_length']\n",
    "    df['dollar_count'] = df['text'].str.count('\\$')\n",
    "    \n",
    "    # Prepare features\n",
    "    X_text = df['text']\n",
    "    X_numeric = df[['text_length', 'word_count', 'exclamation_count', \n",
    "                   'question_count', 'uppercase_ratio', 'dollar_count']]\n",
    "    y = df['label']\n",
    "    \n",
    "    # Split the data\n",
    "    X_text_train, X_text_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
    "        X_text, X_numeric, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining set size: {len(X_text_train)}\")\n",
    "    print(f\"Test set size: {len(X_text_test)}\")\n",
    "    \n",
    "    # Text vectorization with optimized parameters for large dataset\n",
    "    print(\"\\nConverting text to features...\")\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        lowercase=True,\n",
    "        max_features=5000,\n",
    "        min_df=2,\n",
    "        max_df=0.95,\n",
    "        ngram_range=(1, 2)\n",
    "    )\n",
    "    \n",
    "    X_text_train_tfidf = vectorizer.fit_transform(X_text_train)\n",
    "    X_text_test_tfidf = vectorizer.transform(X_text_test)\n",
    "    \n",
    "    # Combine text features with numeric features\n",
    "    from scipy.sparse import hstack\n",
    "    X_train_combined = hstack([X_text_train_tfidf, X_num_train.values])\n",
    "    X_test_combined = hstack([X_text_test_tfidf, X_num_test.values])\n",
    "    \n",
    "    print(f\"\\nCombined feature matrix shape: {X_train_combined.shape}\")\n",
    "    \n",
    "    # STEP 5: Train Multiple Models\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING MULTIPLE MODELS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    models = {\n",
    "        'Naive Bayes': MultinomialNB(),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'SVM': SVC(probability=True, random_state=42)\n",
    "    }\n",
    "    \n",
    "    model_scores = {}\n",
    "    trained_models = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train_combined, y_train)\n",
    "        trained_models[name] = model\n",
    "        \n",
    "        # Cross-validation score\n",
    "        cv_scores = cross_val_score(model, X_train_combined, y_train, cv=5)\n",
    "        \n",
    "        # Test set performance\n",
    "        y_pred = model.predict(X_test_combined)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        model_scores[name] = {\n",
    "            'CV Mean': cv_scores.mean(),\n",
    "            'CV Std': cv_scores.std(),\n",
    "            'Test Accuracy': test_accuracy\n",
    "        }\n",
    "        \n",
    "        print(f\"  CV Score: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
    "        print(f\"  Test Accuracy: {test_accuracy:.3f}\")\n",
    "    \n",
    "    # STEP 6: Detailed Evaluation of Best Model\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DETAILED EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Find best model\n",
    "    best_model_name = max(model_scores.keys(), \n",
    "                         key=lambda x: model_scores[x]['Test Accuracy'])\n",
    "    best_model = trained_models[best_model_name]\n",
    "    \n",
    "    print(f\"\\nBest Model: {best_model_name}\")\n",
    "    print(f\"  Cross-validation mean accuracy: {model_scores[best_model_name]['CV Mean']:.3f}\")\n",
    "    print(f\"  Test accuracy: {model_scores[best_model_name]['Test Accuracy']:.3f}\")\n",
    "    \n",
    "    # Detailed predictions\n",
    "    y_pred_best = best_model.predict(X_test_combined)\n",
    "    y_pred_proba = best_model.predict_proba(X_test_combined)\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\nClassification Report for {best_model_name}:\")\n",
    "    print(classification_report(y_test, y_pred_best, target_names=['Ham', 'Spam']))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_best)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"True Ham, Predicted Ham: {cm[0,0]}\")\n",
    "    print(f\"True Ham, Predicted Spam: {cm[0,1]} (False Positives)\")\n",
    "    print(f\"True Spam, Predicted Ham: {cm[1,0]} (False Negatives)\")\n",
    "    print(f\"True Spam, Predicted Spam: {cm[1,1]}\")\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Ham', 'Spam'], \n",
    "                yticklabels=['Ham', 'Spam'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # STEP 7: Feature Importance Analysis\n",
    "    if best_model_name == 'Logistic Regression':\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TOP SPAM INDICATORS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        feature_names = list(vectorizer.get_feature_names_out()) + \\\n",
    "                       ['text_length', 'word_count', 'exclamation_count', \n",
    "                        'question_count', 'uppercase_ratio', 'dollar_count']\n",
    "        \n",
    "        coefficients = best_model.coef_[0]\n",
    "        \n",
    "        # Top spam indicators\n",
    "        top_spam_indices = coefficients.argsort()[-15:][::-1]\n",
    "        print(\"\\nTop 15 Spam Indicators:\")\n",
    "        for i, idx in enumerate(top_spam_indices, 1):\n",
    "            print(f\"{i:2d}. {feature_names[idx]:20s}: {coefficients[idx]:6.3f}\")\n",
    "        \n",
    "        # Top ham indicators  \n",
    "        top_ham_indices = coefficients.argsort()[:15]\n",
    "        print(\"\\nTop 15 Ham Indicators:\")\n",
    "        for i, idx in enumerate(top_ham_indices, 1):\n",
    "            print(f\"{i:2d}. {feature_names[idx]:20s}: {coefficients[idx]:6.3f}\")\n",
    "    \n",
    "    # STEP 8: Test with New Emails\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TESTING WITH NEW EMAILS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    test_emails = [\n",
    "        \"FREE iPhone 15! Click now to claim your prize! Limited time!\",\n",
    "        \"Hi John, can we reschedule our meeting to tomorrow at 3 PM?\",\n",
    "        \"URGENT: Your bank account will be closed! Update now!\",\n",
    "        \"Your Amazon order #12345 has been delivered to your address\",\n",
    "        \"Make $5000 from home! Easy work, no experience needed!\",\n",
    "        \"Team lunch tomorrow at the new restaurant downtown?\",\n",
    "        \"CONGRATULATIONS! You've won $10000! Send your details now!\",\n",
    "        \"Please find the quarterly report attached for your review\"\n",
    "    ]\n",
    "    \n",
    "    for email in test_emails:\n",
    "        # Create features for the email\n",
    "        email_df = pd.DataFrame({'text': [email]})\n",
    "        email_df['text_length'] = email_df['text'].str.len()\n",
    "        email_df['word_count'] = email_df['text'].str.split().str.len()\n",
    "        email_df['exclamation_count'] = email_df['text'].str.count('!')\n",
    "        email_df['question_count'] = email_df['text'].str.count('\\?')\n",
    "        email_df['uppercase_ratio'] = email_df['text'].str.count(r'[A-Z]') / email_df['text_length']\n",
    "        email_df['dollar_count'] = email_df['text'].str.count('\\$')\n",
    "        \n",
    "        # Transform text\n",
    "        email_tfidf = vectorizer.transform(email_df['text'])\n",
    "        email_numeric = email_df[['text_length', 'word_count', 'exclamation_count', \n",
    "                                 'question_count', 'uppercase_ratio', 'dollar_count']].values\n",
    "        \n",
    "        # Combine features\n",
    "        email_combined = hstack([email_tfidf, email_numeric])\n",
    "        \n",
    "        # Predict\n",
    "        prediction = best_model.predict(email_combined)[0]\n",
    "        confidence = max(best_model.predict_proba(email_combined)[0])\n",
    "        \n",
    "        print(f\"\\nEmail: '{email[:60]}{'...' if len(email) > 60 else ''}'\")\n",
    "        print(f\"Prediction: {'SPAM' if prediction == 1 else 'HAM'}\")\n",
    "        print(f\"Confidence: {confidence:.2f}\")\n",
    "    \n",
    "    print(f\"\\nModel training complete! Best model: {best_model_name}\")\n",
    "    print(f\"Final accuracy: {model_scores[best_model_name]['Test Accuracy']:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Failed to load dataset. Please check the file path and format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ba150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
